{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c15f1e-d240-491f-8534-c5db53e34bb3",
   "metadata": {},
   "source": [
    "### Using Pandas help you to transform the `data` into AI-readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b01446d-a46a-4e83-a0ab-0e62e3a9f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# The columns of X is \"Year\",\"Rating\" and \"Title\", The columns of y is 'meaning'\n",
    "X = [[1968, 86, \"Greetings\"],\n",
    "        [1970, 17, \"Bloody Mama\"],\n",
    "        [1970, np.nan, \"Hi, Mom!\"],\n",
    "        [1971, 40, \"Born to Win\"],\n",
    "        [1973, 98, \"Mean Streets\"],\n",
    "        [np.nan, 88, \"Bang the Drum Slowly\"],\n",
    "        [1974, 97, \"The Godfather\"],\n",
    "        [1976, np.nan, \"The Last Tycoon\"],\n",
    "        [1976, 99, \"Taxi Driver\"],\n",
    "        [1977, 47, \"1900\"]]\n",
    "\n",
    "y = [1, 0, 0, 0, 1, 1, 1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca0e7a-d888-47e8-b30d-a9a40d9140e7",
   "metadata": {},
   "source": [
    "Step1. Interpolate Missing Data with Expected Value of Each Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a54df-7750-41f0-b4f6-ca3b8d0c420a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2b3e66d-f967-43ad-9385-de0af035f157",
   "metadata": {},
   "source": [
    "Step2. Encoding and Scaling the Features of each Samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fdbe9b-a249-402f-aaa2-c293fb3be0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91cd2eb8-3a99-4315-ad2a-6b6be22646ba",
   "metadata": {},
   "source": [
    "Step3. Flitering Unuseful Features based on **Random Forest Importances**, and use these to fit an Optimized **Logistic Regression Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48da83-f486-4dd8-9204-4102e7976dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484020e6-45f8-4f70-8198-da0bff59557b",
   "metadata": {},
   "source": [
    "### Using Above technique to find the best model and preprocessing to Iris Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dba10b2-8f9e-42a6-a4c7-8e7793e47f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "379f0104-9a0e-4c74-a412-94d2c1fb974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " {0: 'malignant', 1: 'benign'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names'], {i: cls for i, cls in enumerate(data['target_names'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc3a22-20a1-47b6-8a50-a4a4fb2af327",
   "metadata": {},
   "source": [
    "Step1. Find a Good Way to Reduce the Dimension of each Samples in **Breast Cancer Wisconsin Dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5ee7f-0e43-495b-b5a1-f2a8b032e5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d49b5b2b-9f01-42e3-b1ef-98ca64e2f7f6",
   "metadata": {},
   "source": [
    "Step2. Using `Train`, `Test` and `Validation` Subset to Evaluate which Model is the best on this Usecase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ae018-fac7-470e-9083-98c347e8a692",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
