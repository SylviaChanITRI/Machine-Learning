{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe12612-159a-4084-8343-9d12dc3741e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing a perceptron learning algorithm in Python\n",
    "# An object-oriented perceptron API \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define a variable \"Perceptron\" with \"object\" as input, which showed the variable \"Perceptron\" is object-oriented.\n",
    "# Use \"class\" to make sure the results of the variable \"Perceptron\" will be saved in memory.\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta:float           # \"eta\" is the Learning Rate. \"eta\" is a value between 0.0 to 1.0 under float.\n",
    "        Learningrate(between 0.0 and 1.0)\n",
    "    n_iter:int          # \"n_iter\" passes over the trainingdataset, which are numbers under int.\n",
    "        Passes over the trainingdataset.\n",
    "    random_state:int    # \"random_state\" is a random number generator seed for random weight initialzation which are numbers under int.\n",
    "        Random number generator seed for random weight initialzation.\n",
    "\n",
    "    Attributes\n",
    "    -------------\n",
    "    w_:1d-array         # \"w_\" is the weight after fitting. \"w_\" is a one dimension array.\n",
    "        weight after fitting.\n",
    "    errors:list         # \"errors\" list the number of misclassifications in every epoch, which means it record the history of fitting. \n",
    "        Number of misclassifications in every epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define a variable \"__init__\"\n",
    "    # Please note that double lower line only used in specific situation. Please make sure do not name a variable with double lower line without careness. \n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):   \n",
    "        self.eta=eta                        # eta of self equals to eta, which has set in the first line of this def loop\n",
    "        self.n_iter=n_iter                  # n_iter of self equals to n_iter, which has set in the first line of this def loop\n",
    "        self.random_state=random_state      # random_state of self equals to random_state, which has set in the first line of this def loop\n",
    "\n",
    "    # Define a variable \"fit\" for fitting training data\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        X:(arrary-like), shape=[n_examples, n_features]        # \"X\" is an array with training vectors\n",
    "        Training vectors, where n_example is the number of examples and n_feature is the number of features.\n",
    "        y:array-like, shape = [n_example]                      # \"y\" is an array with target values\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        self:object\n",
    "        \"\"\"\n",
    "\n",
    "        # call out the function RandomState of random in np, input \"random_state\" of self, output the result saving as \"rgen\"\n",
    "        rgen=np.random.RandomState(self.random_state) \n",
    "        # call out the function \"normal\" of rgen, input paraneter needed, output the result saving as \"w_\", which is the weight after fitting of \"self\"\n",
    "        self.w_=rgen.normal(loc=0.0, scale=0.01, size=1+X.shape[1])\n",
    "        # \"errors\" list the number of misclassifications in every epoch, which means it record the history of fitting. \n",
    "        # saved \"errors\" of \"self\" in an empty array \n",
    "        self.errors_=[]    \n",
    "\n",
    "        for _ in range(delf.n_iter):\n",
    "            errors=0\n",
    "            for xi, target in zip(X, y):  # \"zip\" is a command which can contain two variable at the same time\n",
    "                update=self.eta*(target-self.predict(xi))   # calculate the difference between inference(self.predict(xi)) and reality(target)\n",
    "                self.w_[1:]+=update*xi                      # Use the difference to correct the weight used for fitting\n",
    "                self.w_[0]+=update\n",
    "                errors+=int(update!=0.0)                    # saved the values of \"update\" which are not 0.0, which are the values reflected the function still needs to do fitting to improve\n",
    "            seld.errors_.append(errors)                     # function \"append\" save the latest value of \"errors\" of self to the list of \"errors\"\n",
    "        return self        # retrurn \"self\" as a result\n",
    "\n",
    "    \n",
    "    # Calculate net input\n",
    "    # Define a variable \"net_input\" with input variables \"self\" and \"X\"\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]+self.w_[0])  # Call out the function \"dot\" of np, return the result of weight as results\n",
    "\n",
    "    # Define a variable \"predict\" with input variables \"self\" and \"X\"\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "\n",
    "        # Call out function \"where\" of \"np\"\n",
    "        # Base on the result of \"noet_input(X)\" of \"self\", return 1 as active, retrun -1 as unactive\n",
    "        return np.where(self.net_input(X)>=0.0, 1, -1)\n",
    "\n",
    "\n",
    "# The code below didn't be used.\n",
    "v1=np.array([1, 2, 3])\n",
    "v2=0.5*v1\n",
    "np.arccos(v1.dot(v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d33197-933c-4f2d-bc76-c91afb8b4e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of extension knowledge\n",
    "# Introduce how to call out function\n",
    "\n",
    "model = Perceptron(eta=0.0001, n_iter=10, random_state=2)   # You can customized the value of valuables within the function \"Perceptron\"\n",
    "model.predict(X)  # Call out the function \"predict\" under \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52690be-4046-4612-9000-252c6d67965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of extension knowledge\n",
    "# Introduce how to use the function \"list\"\n",
    "\n",
    "error_list = []                # Create an empty array for a list named \"error_list\". Please mind that need to use \"[]\" for list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a8aee1-474b-4790-b4f4-6dfb83cc867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list.append([1,2,3])     # Use function \"append\" to save the first data to the list array \"error_list\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d343f0f9-6328-4b29-9f3a-ba0831ceb26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, '', [1, 2, 3]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list                     # Command system show you what's in the list array \"error_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe1c38c-60af-4483-bb6e-0fe357b75691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': 1, 'key2': ''}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of extension knowledge\n",
    "# Introduce how to use the function \"dictionary\"\n",
    "\n",
    "error_dict = {}                # Create an empty array for a dictionary named \"error_dict\". Please mind that need to use \"{}\" for dictionary.\n",
    "error_dict['key1'] = 1         # In a dictionary, you will need to let the system know where you with to save your data, such as \"key1\"\n",
    "error_dict['key2'] = \"\"\n",
    "error_dict                     # Command system show you what's in the dictionary array \"error_dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c507fe19-d5d8-4814-bbc2-23532dbc36cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dict['key1']             # Command system show you what's in the dictionary array of location \"key1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78ba84-b4a2-4bc3-b405-ea072ec6522b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
